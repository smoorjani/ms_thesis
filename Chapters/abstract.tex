Adopting contextually appropriate, audience-tailored linguistic styles, namely persuasiveness, is critical to the success of user-centric language generation systems (\eg chatbots, computer-aided writing, dialog systems). While existing approaches demonstrate textual style transfer with large volumes of data, grounding style on audience-independent factors is innately limiting because many stylistic objectives (\eg persuasiveness, memorability, empathy) are hard to define without audience feedback.

In this thesis, we first propose the novel task of \textit{style infusion} - infusing the stylistic preferences of audiences in pretrained language generation models. Since humans are better at pairwise comparisons than direct scoring - \ie \textit{is Sample-A more persuasive than Sample-B} - we leverage limited pairwise human judgments to bootstrap a style analysis model and augment our seed set of judgments. We infuse the learned textual style in a GPT-2 based text generator while balancing fluency and style adoption. With quantitative and novel qualitative assessments, we show that our infusion approach can generate compelling stylized examples with generic text prompts. 

We then utilize complex linguistic features strongly correlated with persuasiveness to guide the generation of sequence-to-sequence models. We explore modifications of two approaches - an edit-then-prototype model and the style infusion architecture - to exhibit a ``tuning-knob''-like control over the speed of text (\ie how quickly content is covered). We empirically show that our modifications lead to strong controls over generated text and discuss directions to improve the fluency and control of generations further.

% While existing approaches demonstrate textual style transfer with large volumes of parallel or non-parallel data, we argue that grounding style on audience-independent external factors is innately limiting for two reasons. First, it is difficult to collect large volumes of audience-specific stylistic data. Second, some stylistic objectives (\eg persuasiveness, memorability, empathy) are hard to define without audience feedback. 

%   Persuasiveness has a widely disputed definition, typically being influenced by external confounds,
%   but in existing literature, there is some agreement on certain features of persuasive text. Current work focuses 
%   on understanding persuasive datasets and finding traits of persuasiveness, but the generation of persuasive tex tis widely unexplored. In this project, we create a framework to generate 
%   persuasive arguments with extremely limited labeled parallel data. We first train a discriminator that takes two arguments and 
%   determines the more persuasive of the pair. The discriminator is then used in an adversarial architecture to provide 
%   feedback to language model. This feedback is used with a discriminator loss which is 
%   weighted with a reconstruction loss to ensure both fluency and persuasiveness. We also provide a data augmentation method
%   using the discriminator to ensure the model produces robust generations. We then compare the generations of our baseline models
%   with our proposed framework on a variety of traits of persuasiveness and show that our generated arguments are more indeed more persuasive. We also show that our framework can be extended to other traits that are difficult to quantify such as memorability.

% Textual style refers to the manner in which semantics is phrased, \ie linguistic variations in conveying the same conceptual content. Persuasiveness, memorability, and empathy are some such valuable human-centric stylistic objectives in dynamic text generation systems such as chatbots and computer-aided writing tools. While humans infer styles by contextually comparing linguistic constructs and phrasing, computational methods to textual style transfer (TST) learn to associate styles with large corpora - \ie given text, the inferred style depends on its distributional similarity to an existing corpus. In this paper, we attempt to merge human-centric lignuistic inference with model-centric data-driven inference of style for targeted language generation. 

% Our approach has two primary motivations: First, styles typically lack well-matched large corpora to train models from scratch and must be tailored to the audience. Second, humans are better at pairwise comparisons than direct scoring - \ie \textit{is Sample-A more persuasive/polite/empathic than parallel Sample-B}? Thus, we leverage pairwise human judgments to bootstrap a discriminative language model and expand our seed set of judgments. We then finetune a GPT-2 based text generator with the discriminative language model while balancing fluency and style transfer. With quantitative and qualitative assessments, we show that our approach can learn to imitate stylistic attributes of text and generate compelling stylized text with generic prompts.
