Recent work discovered that on social media platforms like Twitter, ``Falsehood diffused significantly farther, faster, deeper, and more broadly than the truth in all categories of information.'' \citep{vosoughi2018spread}  Furthermore, the growing loss of faith in scientific expertise in certain groups has accelerated in recent years \citep{gauchat2012politicization}. With the rising concern of scientific misinformation, the diffusion of factually correct content, namely scientific literature, becomes critical. How do we make scientific discoveries more accessible and appealing to the general public? 

Scientific literature is notoriously bland and difficult to interpret by the lay public, who are unfamiliar with the scientific domain. In contrast, well-written newspaper articles about scientific breakthroughs present exciting and accessible information for the layperson. Could more accessible, persuasively written scientific communication be one tool to combat the spread of misinformation? With the increased sophistication of language generation techniques, machines can write more appealing text, altering the level of emotion \citep{ghosh-etal-2017-affect, zhou2018emotional}, generating based on given facts \citep{orbach-goldberg-2020-facts2story}, and understanding the components of structured writing \citep{Tambwekar_2019}. In this thesis, we look to a combination of natural language processing and theoretical constructs from advertising and journalism to make novel advancements in our understanding of persuasion and how to synthesize persuasive content. Specifically, we introduce the novel task of style infusion to motivate unconstrained, stylized text generation and present our approach to generating persuasive text. Then, we explore methods to control specific features correlated with persuasiveness as a method of synthesizing persuasive text. 

In~\Cref{sec:intro_style_infusion}, we introduce style infusion and discuss our efforts to synthesize persuasive text. Then in~\Cref{sec:intro_control}, we explore controllable stylized generation and broadly describe our approaches. Lastly, we outline the rest of the thesis in~\Cref{sec:thesis_outline}.

% We present our contributions in~\Cref{sec:contributions} and outline the rest of the thesis in~\Cref{sec:thesis_outline}.

\section{Style Infusion}
\label{sec:intro_style_infusion}

In~\Cref{chp:style_infusion}, we focus on a novel approach to infuse audience-centric styles into pretrained language generation models. Textual styles - \ie different linguistic presentations of the same conceptual content - play an integral role in persuasive communication. For instance, an informal style is less persuasive in formal settings~\citep{kim2019comparing}. Learning to synthesize these textual styles, especially audience-defined ones, is crucial to various applications, from empathic styling in mental health~\citep{cameron2018assessing} to fact-driven, simplistic styling in tech support~\citep{okuda2018ai}. User-centric applications of text generation, such as writing aids, chatbots, and dialog systems, often require these stylistic adjustments depending on both the audience and the task. 
% For instance, persuasion and memorability in computational advertising and marketing \citep{van-noort-2020-automatic}.

Prior work often defines textual style with large static sentence collections. However, stylistic objectives such as persuasiveness, memorability, and empathy are hard to define without a target audience~\citep{bell1984style} due to non-uniform stylistic expectations across diverse user groups. Thus, we suggest that subjective text styles and traits must be defined by the target audience instead of audience-independent data. Textual style transfer (TST) is a popular approach for generating text that reflects a given style. Existing work in TST takes two general approaches. The strictly supervised methods leverage fixed parallel corpora, analogous to machine translation~\citep{hu2017toward}, while semi-supervised and unsupervised techniques leverage non-parallel collections of stylized sentences~\citep{shen2017style}. Predefined metrics, heuristics, external oracles, and hybrid approaches have also been considered~\citep{jain2019unsupervised, jin2019imat}.

% Our work focuses on two resulting challenges - first, how to collect target audience feedback, and second, how to leverage the limited feedback efficiently for style infusion.

Constructing audience-centric or time-evolving/adaptive methods for style transfer remains an open challenge. Existing approaches are guided by rigid modeling considerations and the distributions of fixed style-specific corpora. This is innately limiting for stylistic objectives such as persuasiveness, a trait with a widely disputed definition in existing literature, and multiple external confounds such as preexisting biases and independent features of the persuader (\eg number of followers) \citep{al-khatib-etal-2020-exploiting,moran-2016,lowrey-1998, berger-2012,murphy-2001}. Furthermore, it is infeasible to collect extensive annotated collections of text for each audience, style, and application~\citep{pennebaker1999linguistic}. 

% In contrast to these prior definitions, we define and incorporate style grounded on our target audience - with explicit audience feedback via pairwise comparisons. 

Unlike prior work, we define and incorporate style grounded on our target audience. To address dynamic settings requiring audience-centric linguistic styles, we propose the novel \textit{style infusion} task. Since human reviewers are better at pairwise style comparisons than direct scoring~\citep{shah-cardinal-ordinal}, we formulate \textit{style infusion} as follows: how do we \textit{infuse} the stylistic preferences of our audience, via pairwise sentence comparisons, in a generative language model (LM)? Unlike conventional style transfer, our task leverages domain and audience-specific feedback instead of parallel sentence collections rendered in any specific style. Further, we adopt an incremental training approach rather than retraining models from scratch. In summary, our contributions are as follows: 

\begin{enumerate}
    \item \textbf{Audience-centric Style Infusion}: To our knowledge, we are the first to formulate the task of style infusion to tether the definition of style to the target audience. In contrast, prior work defines style in a purely data-driven manner~\citep{shen2017style, yang2018unsupervised}. External data limits the definition of style to the context in which it was collected. We propose a more human-centric approach to text styling through explicit audience feedback via pairwise comparisons.
    
    \item \textbf{Decoupling Style}: We decouple the style analysis and language generation models for versatility and simplicity. Prior work often unifies these tasks in a single training setup, thus sacrificing incremental learning and infusion of new stylistic preferences of audiences~\citep{jain2019unsupervised, jin2019imat}. We introduce an automatically weighted loss, combining an independent reconstruction loss for generation and discriminator-based loss for style, producing a more robust representation of style than in fused settings. 

    \item \textbf{Automatic Style Evaluation}: To the best of our knowledge, we are the first to automatically evaluate the transfer of memorability/persuasiveness. Existing literature has relied on costly manual evaluation as these traits are hard-to-define stylistic objectives lacking generative work~\citep{li2020,tan2016,danescu-niculescu-mizil-etal-2012-hello}. We introduce a new audience-centric correlation metric using a hierarchical Bayesian model to compute the correlations of linguistic features with audience feedback. We then evaluate our model's generations based on their agreements with these audience correlations. 
\end{enumerate}

% In Chapter \ref{chp:style_infusion}, we will discuss the approach, experimentation, and results in more detail.

% We bootstrap an initial style analysis model to discriminate the positive and negative samples from audience feedback. Our model then selects additional samples from a generic topical sentence collection to expand the seed set of audience judgments. By separating style analysis and text generation models, we create an adversarial setup to infuse the audience's stylistic feedback in any generative LM. We weight the noisy reward from the style analysis model (discriminator) with a reconstruction loss to balance style adoption and fluency. 

% We develop a bootstrapped approach to augment audience feedback with a generic style-independent topical corpus and learn a textual style analysis model
% In summary, our contributions are as follows: 
% \begin{enumerate}
%     \item \textbf{Audience-centric Style Infusion}: To our knowledge, we are the first to formulate the task of style infusion to tether the definition of style to the target audience. In contrast, prior work defines style in a purely data-driven manner~\citep{shen2017style, yang2018unsupervised}. External data limits the definition of style to the context in which it was collected. We propose a more human-centric approach to text styling through explicit audience feedback via pairwise comparisons.
    
%     \item \textbf{Decoupling Style}: We decouple the style analysis and language generation models for versatility and simplicity. Prior work often unifies these tasks in a single training setup, thus sacrificing incremental learning and infusion of new stylistic preferences of audiences~\citep{jain2019unsupervised, jin2019imat}. We introduce an automatically weighted loss, combining an independent reconstruction loss for generation and discriminator-based loss for style, producing a more robust representation of style than in fused settings. 

%     \item \textbf{Automatic Style Evaluation}: To the best of our knowledge, we are the first to automatically evaluate the transfer of memorability/persuasiveness. Existing literature has relied on costly manual evaluation as these two traits are hard-to-define stylistic objectives lacking generative work~\citep{li2020,tan2016,danescu-niculescu-mizil-etal-2012-hello}. We introduce a new audience-centric correlation metric using a hierarchical Bayesian model to compute the correlations of linguistic features with audience feedback. We then evaluate our model's generations based on their agreements with these audience correlations. 
% \end{enumerate}

\section{Controllable Stylistic Generation}
\label{sec:intro_control}

In~\Cref{chp:control_gen}, we broaden our efforts by exploring controls on target features of generated text. Textual styles, like persuasion, have a strong correlation with certain linguistic features (see Section \ref{sec:pers_results}) \citep{gamon2004linguistic}. Our previous approach infused a learned textual style, comprising many linguistic features, into a generation model, but we aim to generate persuasive text with more fine-grained controls. Controllable text generation is the task of reliably generating text that satisfies specified controllable constraints. User-centric control in generative models has various downstream applications, including storyline control in story generation \citep{peng2018towards}, emotion and toxicity controls in dialogue response generation \citep{lu2022quark, zhou2018emotional}, and more. 

Prior work often focuses on three types of control conditions: semantic (\eg emotion, topics), structural (\eg syntax tree, parts-of-speech), and lexical controls (\eg keyword inclusion) \citep{Zhang2022ASO}. \citet{li2022diffusion} apply diffusion models to text generation with a controlling factor on the latent variables for controlling parts of speech, semantic content, length, and more. \citet{kumar2021controlled} reduce decoding to a multi-constraint optimization problem, claiming control over any number of differentiable constraints such as formality and similarity. Other approaches have been explored on similar control conditions such as control codes \citep{keskar2019ctrl}, class-conditional discriminator-based controls \citep{yang2021fudge}, and ensembling small discriminators for control \citep{krause2020gedi}. 

% Furthermore, existing techniques target individual control conditions and not the composition of multiple controls, a crucial facet of styles like persuasion.

We identify two open problems within controllable text generation: controls incompatible with existing groupings and multiple controls. Prior work is either restricted to singular controls in one of the three control conditions or needs empirical results on the composition of multiple controls, a crucial facet of styles like persuasion. We experiment with existing literature and our approach in~\Cref{sec:intro_style_infusion} to provide insights into the former problem. Specifically, we target speed \citep{toubia-2021}, a measure of how quickly the content in text changes, which does not fit cleanly into the three existing control conditions. 

We propose two methods to condition the output of text generation methods on target tunable features: a modified edit-then-prototype model \citep{guu2018generating} and an adversarial control framework. In the former, we alter the training set and perturb the edit mechanism to reflect a desired change in a given attribute. In the latter, we utilize an attribute regressor to adversarially train a sequence-to-sequence model, controlling the target feature in generations. With these approaches, we hope to create generation models that can adapt to user needs (\eg generating persuasive text) without needing large amounts of domain-specific data or costly regeneration of text. In summary, our contributions are as follows: 

\begin{enumerate}
    \item \textbf{Controllable Generation}: We propose simple modifications to prior works \citep{guu2018generating, moorjani-etal-2022-audience} to allow for controllable text generation in both an autoregressive and non-autoregressive setting. We show that our generations exhibit significant control of speed while preserving lexical and semantic similarity to the original sequence.
    \item \textbf{Nonstandard Controls}: To our knowledge, we are the first to attempt controllable text generation on features that are not encompassed by existing control conditions of prior works (\ie semantic, structural, or lexical). We demonstrate through both approaches that control is possible on features such as speed \citep{toubia-2021}.
\end{enumerate}

% We experiment with existing literature to provide insight into these questions, namely through utilizing a trained stylistic classifier that aggregates desired stylistic controls. By conditioning the output of text generation methods based on specific features, we hope to create generation models that can adapt to target audiences without the need for large amounts audience-specific data.

% In Chapter \ref{chp:control_gen}, we discuss our approaches, experimentation, and results in more detail.

% \section{Contributions}
% \label{sec:contributions}

\section{Thesis Outline}
\label{sec:thesis_outline}
The remainder of this thesis is organized as follows:

\begin{itemize}
    \item Chapter \ref{chp:relworks} discusses the relevant literature surrounding persuasion (among other similar styles) along with existing work on textual style transfer and controlled generation.
    \item In Chapter \ref{chp:style_infusion}, we propose an audience-centric style infusion mechanism for the open generation of persuasive/memorable text. We show that decoupling style analysis and language generation during training produces a more robust representation of style than in fused settings on a novel automatic style evaluation metric.
    \item In Chapter \ref{chp:control_gen}, we present various controllable text generation approaches, based on previous literature and our approach in~\Cref{chp:style_infusion}, to establish a ``tuning knob''-like control for linguistic features (\eg speed).  
    \item Chapter \ref{chp:concl} and \ref{chp:future} conclude this thesis and present some future directions. We also include sections to consider the limitations and ethical impact of our research.
\end{itemize}